{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dota 2: Winner Prediction\n",
    "The task is to predict the winner (either **Dire** or **Radiant** team) based on data from the first 5 minutes of the match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "train = pd.read_csv('features.csv',\n",
    "                    index_col='match_id')\n",
    "test = pd.read_csv('features_test.csv',\n",
    "                   index_col='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target column: radiant_win\n"
     ]
    }
   ],
   "source": [
    "# preparing cross-validation, target and scaler\n",
    "cv = KFold(n_splits=5,\n",
    "               shuffle=True,\n",
    "               random_state=173)\n",
    "scaler = StandardScaler()\n",
    "y = train.iloc[:, 103]\n",
    "print(f'target column: radiant_win')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values in data by columns:\n",
      "first_blood_time               19553\n",
      "first_blood_team               19553\n",
      "first_blood_player1            19553\n",
      "first_blood_player2            43987\n",
      "radiant_bottle_time            15691\n",
      "radiant_courier_time             692\n",
      "radiant_flying_courier_time    27479\n",
      "radiant_first_ward_time         1836\n",
      "dire_bottle_time               16143\n",
      "dire_courier_time                676\n",
      "dire_flying_courier_time       26098\n",
      "dire_first_ward_time            1826\n",
      "dtype: int64\n",
      "\n",
      "explanation for 2 columns with missing values:\n",
      "1. in 'radiant_bottle_time': probably, in 15691 matches the 'bottle' item was\n",
      "   never purchased by the Radiant team.\n",
      "2. in 'dire_first_ward_time': presumably, in 1826 matches the Dire team never\n",
      "   planted the Ward.\n"
     ]
    }
   ],
   "source": [
    "# finding missing data, explaining some, and filling with zeroes (better for logistic regression)\n",
    "missing = train.isna().sum()\n",
    "missing = missing[missing > 0]\n",
    "\n",
    "print(f'''missing values in data by columns:\n",
    "{missing}\n",
    "\n",
    "explanation for 2 columns with missing values:\n",
    "1. in 'radiant_bottle_time': probably, in 15691 matches the 'bottle' item was\n",
    "   never purchased by the Radiant team.\n",
    "2. in 'dire_first_ward_time': presumably, in 1826 matches the Dire team never\n",
    "   planted the Ward.''')\n",
    "\n",
    "train.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trees: 30\n",
      "learning rate: 0.5\n",
      "time: 66.22533183097839\n",
      "score: 0.7034352666054644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initializing hyperparameter grid and the model itself\n",
    "gb = GradientBoostingClassifier(random_state=173)\n",
    "grid = {'learning_rate': [1, 0.5, 0.3, 0.2, 0.1],\n",
    "        'n_estimators': np.arange(10, 60, 10)}\n",
    "gs = GridSearchCV(\n",
    "    gb,\n",
    "    grid,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    cv=cv\n",
    ")\n",
    "\n",
    "gs.fit(train.iloc[:, :102], y)\n",
    "\n",
    "# extracting info from search\n",
    "gs_results = pd.DataFrame(gs.cv_results_)\n",
    "optimal_rate = gs.best_params_['learning_rate']\n",
    "_30_trees = gs_results[\n",
    "    (gs_results.param_learning_rate == gs.best_params_['learning_rate']) &\n",
    "    (gs_results.param_n_estimators == 30)\n",
    "]\n",
    "\n",
    "# completing the task: providing info on cv with 30 trees\n",
    "print(f'''number of trees: 30\n",
    "learning rate: {optimal_rate}\n",
    "time: {_30_trees.mean_fit_time.values[0]}\n",
    "score: {_30_trees.mean_test_score.values[0]}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2-regulator: [0.01]\n",
      "time: <= 10 seconds\n",
      "score: 0.7164074592058913\n"
     ]
    }
   ],
   "source": [
    "# initializing hyperparameter grid and the model itself\n",
    "Cs = np.concatenate((np.arange(.01, .1, .01), np.arange(.1, 1.05, .05)))\n",
    "logreg = LogisticRegressionCV(\n",
    "    Cs=Cs,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    solver='saga',\n",
    "    n_jobs=-1,\n",
    "    random_state=173\n",
    ")\n",
    "\n",
    "# fitting scaled data\n",
    "logreg.fit(scaler.fit_transform(train.iloc[:, :102]), y)\n",
    "\n",
    "# completing the task: providing info on cv\n",
    "print(f'''l2-regulator: {logreg.C_}\n",
    "time: <= 10 seconds\n",
    "score: {logreg.scores_[1].mean(axis=0).max()}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3: logistic regression without categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2-regulator: [0.01]\n",
      "time: <= 10 seconds\n",
      "score: 0.7164602235577593\n"
     ]
    }
   ],
   "source": [
    "categories = [f'{team}{digit}_hero' for team in 'rd' for digit in range(1, 6)]\n",
    "categories.append('lobby_type')\n",
    "\n",
    "X_no_cat_scaled = scaler.fit_transform(\n",
    "    train.iloc[:, :102].drop(categories, axis=1))\n",
    "\n",
    "logreg.fit(X_no_cat_scaled, y)\n",
    "\n",
    "# completing the task: providing info on cv\n",
    "print(f'''l2-regulator: {logreg.C_}\n",
    "time: <= 10 seconds\n",
    "score: {logreg.scores_[1].mean(axis=0).max()}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 4: logistic regression with dummy coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2-regulator: [0.04]\n",
      "time: <= 20 seconds\n",
      "score: 0.7519508176437737\n"
     ]
    }
   ],
   "source": [
    "# amount of unique players\n",
    "n_players = max(np.unique(train[categories]))\n",
    "\n",
    "# creating a bag of words for players\n",
    "bag = np.empty((train.shape[0], n_players), dtype=int)\n",
    "\n",
    "# barbaric way of filling array provided by the course's authors\n",
    "for i, match_id in enumerate(train.index):\n",
    "    for p in range(1, 6):\n",
    "        bag[i, train.loc[match_id, f'r{p}_hero']-1] = 1\n",
    "        bag[i, train.loc[match_id, f'd{p}_hero']-1] = -1\n",
    "\n",
    "logreg.fit(np.hstack((X_no_cat_scaled, bag)), y)\n",
    "\n",
    "# completing the task: providing info on cv\n",
    "print(f'''l2-regulator: {logreg.C_}\n",
    "time: <= 20 seconds\n",
    "score: {logreg.scores_[1].mean(axis=0).max()}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most probable Radiant win: 0.9962849889082319\n",
      "most probable Dire win: 0.008395380987806138\n"
     ]
    }
   ],
   "source": [
    "# preprocessing test data in the same way\n",
    "test.fillna(value=0,\n",
    "            inplace=True)\n",
    "test_bag = np.empty((test.shape[0], n_players))\n",
    "for i, match_id in enumerate(test.index):\n",
    "    for p in range(1, 6):\n",
    "        test_bag[i, test.loc[match_id, f'r{p}_hero']-1] = 1\n",
    "        test_bag[i, test.loc[match_id, f'd{p}_hero']-1] = -1\n",
    "X_test_bag = np.hstack((\n",
    "    scaler.transform(test.drop(categories, axis=1)),\n",
    "    test_bag\n",
    "))\n",
    "\n",
    "# final stage: prediction\n",
    "answer = logreg.predict_proba(X_test_bag)[:, 1]\n",
    "print(f'''most probable Radiant win: {max(answer)}\n",
    "most probable Dire win: {min(answer)}''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit4edd3680f1b04c5489cd1c2045ec8111"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
